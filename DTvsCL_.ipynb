{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaned vs Dirty \n\n# За основу решения взята baseline от авторов курса ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport copy\nimport torch\nimport random\nimport joblib\nimport shutil\nimport zipfile\nimport torchvision\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torchvision.transforms.functional as transf\n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torchvision import datasets, transforms, models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Распаковка и создание train и val директорий для дальнейшего формирования датасетов  \nwith zipfile.ZipFile('../input/platesv2/plates.zip', 'r') as zip_obj:\n    zip_obj.extractall('/kaggle/working/')\n\ndata_root = '/kaggle/working/plates/'\n\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\nfor dir_name in ['train', 'val']:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\n# Распределение на train (16 img) и val (4 img) выборку для каждого из классов 'cleaned', 'dirty'     \nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    names = os.listdir(source_dir)\n    names.remove('.DS_Store')\n    for i, file_name in enumerate(names):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Блок определения аугментаций и формирования train и val датасетов\n\n# Список применяемых аугментаций:\n#     - center_crop = img вырезается из центра исходника, size = (224,224) \n#     - resize      = исходник сжимается до size = (224,224) \n#     - Hflip       = горизонтальное отзеркаливание  \n#     - Vflip       = вертикальное отзеркаливание  \n#     - canny       = применение детектора Canny с наложением на img полученных граней \n# Аугментации определены через класс TF_data.\n\n# Состав train датасета (128 img):\n#      [0] 16 dirty img + 16 cleaned img, аугментации - center_crop, canny                                      \n#      [1] 16 dirty img + 16 cleaned img, аугментации - center_crop, Hflip, canny\n#      [2] 16 dirty img + 16 cleaned img, аугментации - center_crop, Vflip, canny\n#      [3] 16 dirty img + 16 cleaned img, аугментации - center_crop\n                                       \n# Состав val датасета (8 img):\n#      [0] 4 dirty img + 4 cleaned img, аугментации - resize, canny\n\n# batch_size принят равным 4 (при увеличении наблюдалось снижение accuracy). \n# Итоговый размер train_dataloader - 32 батча из 128 img\n\nmean_ = [0.485, 0.456, 0.406]\nstd_ = [0.229, 0.224, 0.225]\n\nclass TF_data(): \n    def __init__(self, center_crop=False, resize=False, Hflip=False, Vflip=False, canny=False):\n        self.center_crop = center_crop\n        self.resize = resize\n        self.Hflip = Hflip\n        self.Vflip = Vflip\n        self.canny = canny\n    \n    def __call__(self, img):\n        if self.resize:\n            img = transf.resize(img, (224,224))\n        if self.center_crop:\n            img = transf.center_crop(img, 224)\n        if self.Hflip:\n            img = transf.hflip(img)\n        if self.Vflip:\n            img = transf.vflip(img)\n        if self.canny:\n            im = np.asarray(img)\n            edges = cv2.Canny(im,90,180)\n            edges = cv2.cvtColor(edges,cv2.COLOR_GRAY2RGB)\n            res = cv2.addWeighted(im,0.7,edges,0.3,0)\n            img = Image.fromarray(res)\n\n        img = transf.normalize(transf.to_tensor(img), mean_, std_)                 \n        return img\n\nset_data = [0 for i in range(4)]\n\nset_data[0] = datasets.ImageFolder(train_dir, TF_data(center_crop=True, canny=True))\nset_data[1] = datasets.ImageFolder(train_dir, TF_data(center_crop=True, Hflip=True, canny=True))\nset_data[2] = datasets.ImageFolder(train_dir, TF_data(center_crop=True, Vflip=True, canny=True))\nset_data[3] = datasets.ImageFolder(train_dir, TF_data(center_crop=True))\n\ntrain_dataset = torch.utils.data.ConcatDataset(set_data)\n\nval_transforms = TF_data(resize=True, canny=True)\nval_dataset = datasets.ImageFolder(val_dir, val_transforms)\n\nbatch_size = 4\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataloader), len(train_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndef show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция режима тренировки модели. Относительно baseline внесено одно изменение - \n# - scheduler.step() выполняется после optimizer.step() согласно рекомендации PyTorch Doc\n\ndef train_model(model, loss, optimizer, scheduler, num_epochs):\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                model.train()\n            else:\n                dataloader = val_dataloader\n                model.eval()\n\n            running_loss = 0.\n            running_acc = 0.\n\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n                \n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n                \n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n            \n            train_loss_history[phase].append(epoch_loss)\n            train_acc_history[phase].append(epoch_acc)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n            \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Задача классификации решалась с использованием обученных моделей из библиотеки PyTorch.  \n# В результате нескольких экспериментов была выбрана модель mobilenet_v2. \n# Базовый классификатор модели был изменен добавлением дополнительных полносвязных слоев с функцией активации ReLU6 и \n# дропаутом. Проводились эксперименты  с постепенным увеличением Linear-слоев с 1-го до 3-х. \n# Увеличение количества полносвязных слоев дало увеличение accuracy с 0.93817 (на 10 эпохах обучения) до 0.96370 (на 30 эпохах обучения)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Загрузка обученной модели с измененным классификатором  \n\ndef reload():\n    model = models.mobilenet_v2(pretrained=True)\n    \n    i = model.classifier[1].in_features\n    m = model.classifier[1].in_features // 3\n\n    model.classifier = torch.nn.Sequential(\n                                          torch.nn.Dropout(0.2),\n                                          torch.nn.Linear(i, m),        # 1280 --> 426 нейронов\n                                          torch.nn.ReLU6(),\n                                          torch.nn.Linear(m, m // 2 ),  # 426 --> 213 нейронов\n                                          torch.nn.ReLU6(),\n                                          torch.nn.Dropout(0.2),\n                                          torch.nn.Linear(m // 2, 2)    # 213 --> 2 нейрона\n                                          )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучение модели\n# Идея получения наилучшего результата заключается в выборе best_model путем перебора 10-и seed'ов (history) и \n# сравниванием значений mean_loss и mean_acc для каждой обученной модели. \n# Чем выше acc и меньше loss (для моделей с одинаковым mean_acc), тем предпочтительней модель.\n# Модель обучалась 30 эпох с понижением скорости обучения на каждой эпохе в 2 раза.\n\ntorch.backends.cudnn.deterministic = True\n\nhistory = 10\nnum_epochs = 30\nmean_acc = [0 for i in range(history)]\nmean_loss = [1 for i in range(history)]\n\nlr = 0.002\nmomentum = 0.9\nweight_decay = 0.1\nstep_size = 1\ngamma = 0.5\n\nfor i in range(history):\n    random.seed(i)               \n    np.random.seed(i)\n    torch.manual_seed(i)\n    torch.cuda.manual_seed(i)\n    \n    train_loss_history = {'train':[], 'val':[]}\n    train_acc_history = {'train':[], 'val':[]}\n\n    model = reload()  # загрузка модели\n    \n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    loss = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n    \n    train_model(model, loss, optimizer, scheduler, num_epochs=num_epochs); # обучение модели\n    \n    mean_loss[i] = sum(train_loss_history['val'])/len(train_loss_history['val'])\n    mean_acc[i] = sum(train_acc_history['val'])/len(train_acc_history['val'])\n    \n    # сохранение best_model, статистик и seed\n    if mean_acc[:i] == [] or \\\n       mean_acc[i] > max(mean_acc[:i]) or \\\n      (mean_acc[i] == max(mean_acc[:i]) and mean_loss[i] < min(mean_loss[:i])):\n            \n        best_model = model\n        best_seed = i\n        best_train_loss_history = train_loss_history\n        best_train_acc_history = train_acc_history \n        \n    print('history: {:.1f} mean_loss: {:.4f} mean_acc: {:.4f}'.format(i, mean_loss[i], mean_acc[i]), flush=True)\n    \nprint('best_history: {:.1f} mean_loss: {:.4f} mean_acc: {:.4f}'.format(best_seed, mean_loss[best_seed], mean_acc[best_seed]), flush=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вывод графика по acc\nplt.plot(best_train_acc_history['train'], label='train')\nplt.plot(best_train_acc_history['val'], label='val')\nplt.legend(loc='lower right')\nplt.xlabel('$Epoch$')\nplt.ylabel('$Acc$')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Вывод графика по loss\nplt.plot(best_train_loss_history['train'], label='train')\nplt.plot(best_train_loss_history['val'], label='val')\nplt.legend(loc='upper right')\nplt.xlabel('$Epoch$')\nplt.ylabel('$Loss$')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Формирование test_dataset и test_dataloader. \n# Для test_dataset применяются аугментации resize и canny\n\nclass ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \ntest_dataset = ImageFolderWithPaths('/kaggle/working/test', val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переключение best_model в eval режим и составление predictions для test выборки\n\nbest_model.eval()\n\ntest_predictions = []\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = best_model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs, labels, paths = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\n\nsubmission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.58 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('/kaggle/working/test/unknown/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(n=40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохранение модели в файл\n\nfilename = '/kaggle/working/best_model.sav'\njoblib.dump(best_model, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf train val test","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}